{
  # Engine settings
  "model": "conv3d_sep2_on_all_mots",
  "task": "train_no_val",
  "dataset": "MOTS_challenge",
  "log_verbosity": 5,
  "gpus": 1,
  #"own_dataset_per_gpu": true,
  "use_summaries": false,
  "write_summaries": false,
  "collect_run_metadata": false,

  # MaskRCNN on/off
  "add_masks": true,

  # Pretrained model from tensorpack
  "load_init": "globalwork/krause/pretrained_models/trackrcnn_init/converted",
  # Freeze applies to the whole model, not just our backend, but that's fine since only the backend uses batchnorm
  "freeze_batchnorm": true,
  "max_saves_to_keep": 1,

  # Training settings
  "batch_size": 8,
  "learning_rates": "{1: 0.0000005}",
  "optimizer": "adam",
  "num_epochs": 5,
  "max_saves_to_keep": 1,

  # Dataset options
 # "copy_dataset_to_tmp": true,

  "KITTI_segtrack_data_dir": "/globalwork/krause/data/KITTI_MOTS/train/",
  "MOTS_challenge_data_dir": "/globalwork/krause/data/MOTSChallenge/train/",
  "MOTS_challenge_test_data_dir": "/globalwork/krause/data/MOTS_challenge/test/",
  "optical_flow_path": "/globalwork/krause/data/KITTI_flow_pwc/",
  "prefer_gt_to_ignore": true,
  "use_ioa_for_ignore": true,
  "use_masks_for_ignore": true,
  "resize_mode_train": "resize_min_short_edge_max_long_edge",
  "input_size_train": [420, 747],
  "resize_mode_val": "resize_min_short_edge_max_long_edge",
  "input_size_val": [420, 1024],


  "augmentors_train": ["flip", "gamma"],
  "num_parallel_calls": 8,
  "prefetch_buffer_size": 8,

  "mask_disjoint_strategy": "score",
"tracker": "hungarian", "tracker_reid_comp": "euclidean", "detection_confidence_threshold_car": 0.8469800990815324, "reid_weight_car": 1.0, "mask_iou_weight_car": 0.0, "bbox_center_weight_car": 0.0, "bbox_iou_weight_car": 0.0, "association_threshold_car": 0.8165986526897969, "keep_alive_car": 4, "reid_euclidean_offset_car": 8.810218833503743, "reid_euclidean_scale_car": 1.0090931467228708,
"detection_confidence_threshold_pedestrian": 0.9721997956902924, "reid_weight_pedestrian": 1.0, "mask_iou_weight_pedestrian": 0.0, "bbox_center_weight_pedestrian": 0.0, "bbox_iou_weight_pedestrian": 0.0, "association_threshold_pedestrian": 0.9273090046064475, "keep_alive_pedestrian": 9, "reid_euclidean_offset_pedestrian": 9.176847347961733, "reid_euclidean_scale_pedestrian": 1.1158137190659225,

  "network": {
    "resnetconv4": {"class": "ResNet101Conv4"},
    "conv3d_1": {"class": "SepConv3DOverBatch", "activation": "relu", "n_features": 1024, "init_type": "identity", "from": ["resnetconv4"], "old_order": true},
    "conv3d_2": {"class": "SepConv3DOverBatch", "activation": "relu", "n_features": 1024, "init_type": "identity", "from": ["conv3d_1"], "old_order": true},
    "frcnn": {"class": "FasterRCNN", "fastrcnn_batch_per_img": 64, "reid_dimension": 128, "reid_loss_per_class": true,
              "reid_loss_factor": 1.0, "reid_loss_variant": 1, "reid_measure": "euclidean", "from": ["conv3d_2"],
              "class_agnostic_box_and_mask_heads": true}
  }
}

